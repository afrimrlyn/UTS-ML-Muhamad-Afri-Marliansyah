{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K2CHtuKYBaM",
        "outputId": "4a2d49a9-dfe2-4726-ff92-b63b6a3def1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully loaded!\n",
            "Columns renamed successfully to: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64', 'x65', 'x66', 'x67', 'x68', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84', 'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91']\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7313 entries, 0 to 7312\n",
            "Data columns (total 91 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   x1      7313 non-null   int64  \n",
            " 1   x2      7313 non-null   float64\n",
            " 2   x3      7312 non-null   float64\n",
            " 3   x4      7312 non-null   float64\n",
            " 4   x5      7312 non-null   float64\n",
            " 5   x6      7312 non-null   float64\n",
            " 6   x7      7312 non-null   float64\n",
            " 7   x8      7312 non-null   float64\n",
            " 8   x9      7312 non-null   float64\n",
            " 9   x10     7312 non-null   float64\n",
            " 10  x11     7312 non-null   float64\n",
            " 11  x12     7312 non-null   float64\n",
            " 12  x13     7312 non-null   float64\n",
            " 13  x14     7312 non-null   float64\n",
            " 14  x15     7312 non-null   float64\n",
            " 15  x16     7312 non-null   float64\n",
            " 16  x17     7312 non-null   float64\n",
            " 17  x18     7312 non-null   float64\n",
            " 18  x19     7312 non-null   float64\n",
            " 19  x20     7312 non-null   float64\n",
            " 20  x21     7312 non-null   float64\n",
            " 21  x22     7312 non-null   float64\n",
            " 22  x23     7312 non-null   float64\n",
            " 23  x24     7312 non-null   float64\n",
            " 24  x25     7312 non-null   float64\n",
            " 25  x26     7312 non-null   float64\n",
            " 26  x27     7312 non-null   float64\n",
            " 27  x28     7312 non-null   float64\n",
            " 28  x29     7312 non-null   float64\n",
            " 29  x30     7312 non-null   float64\n",
            " 30  x31     7312 non-null   float64\n",
            " 31  x32     7312 non-null   float64\n",
            " 32  x33     7312 non-null   float64\n",
            " 33  x34     7312 non-null   float64\n",
            " 34  x35     7312 non-null   float64\n",
            " 35  x36     7312 non-null   float64\n",
            " 36  x37     7312 non-null   float64\n",
            " 37  x38     7312 non-null   float64\n",
            " 38  x39     7312 non-null   float64\n",
            " 39  x40     7312 non-null   float64\n",
            " 40  x41     7312 non-null   float64\n",
            " 41  x42     7312 non-null   float64\n",
            " 42  x43     7312 non-null   float64\n",
            " 43  x44     7312 non-null   float64\n",
            " 44  x45     7312 non-null   float64\n",
            " 45  x46     7312 non-null   float64\n",
            " 46  x47     7312 non-null   float64\n",
            " 47  x48     7312 non-null   float64\n",
            " 48  x49     7312 non-null   float64\n",
            " 49  x50     7312 non-null   float64\n",
            " 50  x51     7312 non-null   float64\n",
            " 51  x52     7312 non-null   float64\n",
            " 52  x53     7312 non-null   float64\n",
            " 53  x54     7312 non-null   float64\n",
            " 54  x55     7312 non-null   float64\n",
            " 55  x56     7312 non-null   float64\n",
            " 56  x57     7312 non-null   float64\n",
            " 57  x58     7312 non-null   float64\n",
            " 58  x59     7312 non-null   float64\n",
            " 59  x60     7312 non-null   float64\n",
            " 60  x61     7312 non-null   float64\n",
            " 61  x62     7312 non-null   float64\n",
            " 62  x63     7312 non-null   float64\n",
            " 63  x64     7312 non-null   float64\n",
            " 64  x65     7312 non-null   float64\n",
            " 65  x66     7312 non-null   float64\n",
            " 66  x67     7312 non-null   float64\n",
            " 67  x68     7312 non-null   float64\n",
            " 68  x69     7312 non-null   float64\n",
            " 69  x70     7312 non-null   float64\n",
            " 70  x71     7312 non-null   float64\n",
            " 71  x72     7312 non-null   float64\n",
            " 72  x73     7312 non-null   float64\n",
            " 73  x74     7312 non-null   float64\n",
            " 74  x75     7312 non-null   float64\n",
            " 75  x76     7312 non-null   float64\n",
            " 76  x77     7312 non-null   float64\n",
            " 77  x78     7312 non-null   float64\n",
            " 78  x79     7312 non-null   float64\n",
            " 79  x80     7312 non-null   float64\n",
            " 80  x81     7312 non-null   float64\n",
            " 81  x82     7312 non-null   float64\n",
            " 82  x83     7312 non-null   float64\n",
            " 83  x84     7312 non-null   float64\n",
            " 84  x85     7312 non-null   float64\n",
            " 85  x86     7312 non-null   float64\n",
            " 86  x87     7312 non-null   float64\n",
            " 87  x88     7312 non-null   float64\n",
            " 88  x89     7312 non-null   float64\n",
            " 89  x90     7312 non-null   float64\n",
            " 90  x91     7312 non-null   float64\n",
            "dtypes: float64(90), int64(1)\n",
            "memory usage: 5.1 MB\n",
            "None\n",
            "\n",
            "First five rows:\n",
            "     x1        x2        x3        x4        x5        x6        x7        x8  \\\n",
            "0  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
            "1  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
            "2  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
            "3  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
            "4  2001  50.54767   0.31568  92.35066  22.38696 -25.51870 -19.04928  20.67345   \n",
            "\n",
            "         x9       x10  ...       x82        x83       x84       x85       x86  \\\n",
            "0  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n",
            "1  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n",
            "2 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n",
            "3  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n",
            "4  -5.19943   3.63566  ...   6.59753  -50.69577  26.02574  18.94430  -0.33730   \n",
            "\n",
            "        x87        x88       x89        x90       x91  \n",
            "0 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
            "1  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
            "2  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
            "3  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
            "4   6.09352   35.18381   5.00283  -11.02257   0.02263  \n",
            "\n",
            "[5 rows x 91 columns]\n",
            "\n",
            "Descriptive statistics:\n",
            "                x1           x2           x3           x4           x5  \\\n",
            "count  7313.000000  7313.000000  7312.000000  7312.000000  7312.000000   \n",
            "mean   1999.052919    43.553220     1.790834     8.857487     1.775125   \n",
            "std      10.149151     6.035377    50.075482    34.141605    15.474243   \n",
            "min    1930.000000    15.397530  -265.265710  -161.801660   -72.999660   \n",
            "25%    1995.000000    40.115150   -24.393025    -9.994117    -7.583340   \n",
            "50%    2002.000000    44.476780     8.664175    11.004955    -0.005265   \n",
            "75%    2006.000000    48.027530    35.993800    28.841628     8.946653   \n",
            "max    2010.000000    57.302730   304.266390   233.167660   112.688390   \n",
            "\n",
            "                x6           x7           x8           x9          x10  ...  \\\n",
            "count  7312.000000  7312.000000  7312.000000  7312.000000  7312.000000  ...   \n",
            "mean     -6.821706    -9.437239    -1.772331    -1.749754     3.878633  ...   \n",
            "std      22.575318    12.999465    13.677980     7.830437    10.131978  ...   \n",
            "min    -109.577020   -55.861450   -96.656410   -46.321820   -70.918790  ...   \n",
            "25%     -21.575418   -18.586465    -9.859258    -6.467875    -2.109718  ...   \n",
            "50%      -6.666305   -11.065635    -1.609310    -1.542330     3.915330  ...   \n",
            "75%       7.618678    -2.278520     6.849543     3.022705     9.811903  ...   \n",
            "max     262.068870    65.624630   111.529610    52.993750    75.038510  ...   \n",
            "\n",
            "               x82          x83          x84          x85          x86  \\\n",
            "count  7312.000000  7312.000000  7312.000000  7312.000000  7312.000000   \n",
            "mean     15.910751   -70.839097    42.759231    41.623147    -0.468017   \n",
            "std      32.935041   164.753447   127.586344    99.867370    15.962057   \n",
            "min    -424.517570 -1650.756890 -1256.181470 -1412.660510  -130.674300   \n",
            "25%      -1.711865  -141.937230   -22.393367    -1.757240    -7.450662   \n",
            "50%       8.745900   -53.142770    31.146925    36.093045     0.209385   \n",
            "75%      25.396690    15.582260    92.049483    79.939760     7.658720   \n",
            "max     388.227820  1672.084480  2460.628530  1482.642140   113.028260   \n",
            "\n",
            "               x87          x88          x89          x90          x91  \n",
            "count  7312.000000  7312.000000  7312.000000  7312.000000  7312.000000  \n",
            "mean     16.018873   -26.493263     4.988416    21.057812     1.271747  \n",
            "std     114.634662   167.714251    14.351296   188.991650    22.101965  \n",
            "min   -1445.231500 -1759.178190   -77.638720 -1734.946520  -177.403100  \n",
            "25%     -31.319730  -101.362877    -2.459140   -62.803605    -8.829473  \n",
            "50%      15.772990   -20.974110     3.318885     6.095855    -0.037955  \n",
            "75%      66.717395    49.098758    10.273955    84.773605     9.626538  \n",
            "max    1125.880950  1549.195600   203.649480  2559.572110   274.984190  \n",
            "\n",
            "[8 rows x 91 columns]\n",
            "Duplicates removed. Data now has 7312 rows and 91 columns.\n",
            "Target column 'x1' successfully separated.\n",
            "Selected features based on correlation threshold: ['x2', 'x4', 'x7', 'x37', 'x41', 'x47', 'x48', 'x54', 'x58', 'x64', 'x68', 'x74']\n",
            "Low variance features removed.\n",
            "Data after variance thresholding has 12 features.\n",
            "Target column added back to the processed data.\n",
            "Processed dataset saved successfully!\n",
            "Processed dataset saved as: /content/RegresiUTSTelkomNEW.csv\n",
            "Final dataset shape: (7312, 13)\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Provide the file path to your dataset\n",
        "file_path = \"/content/RegresiUTSTelkom.csv\"\n",
        "try:\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(\"Dataset successfully loaded!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found at {file_path}. Please check the file path and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Rename columns to x1, x2, ..., xn\n",
        "column_names = [f'x{i+1}' for i in range(data.shape[1])]\n",
        "data.columns = column_names  # Ensure column renaming is clean\n",
        "print(\"Columns renamed successfully to:\", column_names)\n",
        "\n",
        "# Show basic info and first few rows\n",
        "print(\"Dataset Information:\")\n",
        "print(data.info())\n",
        "print(\"\\nFirst five rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Descriptive statistics\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Step 3: Drop duplicate rows (if not done already)\n",
        "data = data.drop_duplicates()\n",
        "print(f\"Duplicates removed. Data now has {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
        "\n",
        "# Step 4: Remove Target Column (Assuming target is 'x1') for Feature Selection\n",
        "try:\n",
        "    target = data['x1']\n",
        "    data = data.drop(columns=['x1'])\n",
        "    print(\"Target column 'x1' successfully separated.\")\n",
        "except KeyError:\n",
        "    print(\"Target column 'x1' not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Step 5: Identifying and Removing Low Correlation Features with Target\n",
        "correlation_threshold = 0.1  # Threshold for correlation\n",
        "correlation_with_target = data.corrwith(target).abs()  # Correlation with target\n",
        "selected_features = correlation_with_target[correlation_with_target > correlation_threshold].index\n",
        "\n",
        "if selected_features.empty:\n",
        "    print(\"No features found with correlation above the threshold.\")\n",
        "    exit()\n",
        "else:\n",
        "    data_selected = data[selected_features]\n",
        "    print(f\"Selected features based on correlation threshold: {selected_features.tolist()}\")\n",
        "\n",
        "# Step 6: Variance Threshold to Remove Low Variance Features\n",
        "variance_threshold = 0.1  # Threshold for variance\n",
        "selector = VarianceThreshold(threshold=variance_threshold)\n",
        "try:\n",
        "    data_high_variance = selector.fit_transform(data_selected)\n",
        "    print(\"Low variance features removed.\")\n",
        "except ValueError:\n",
        "    print(\"Error: No feature met the variance threshold. Adjust the threshold and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Convert data_high_variance back to DataFrame after Variance Threshold\n",
        "data_final = pd.DataFrame(data_high_variance, columns=[col for col, keep in zip(data_selected.columns, selector.get_support()) if keep])\n",
        "print(f\"Data after variance thresholding has {data_final.shape[1]} features.\")\n",
        "\n",
        "# Step 7: Add the target column back to the processed data\n",
        "data_final['x1'] = target.values[:data_final.shape[0]]  # Adjusting if rows were dropped during processing\n",
        "print(\"Target column added back to the processed data.\")\n",
        "\n",
        "# Step 8: Save the processed dataset\n",
        "processed_file_path = \"/content/RegresiUTSTelkomNEW.csv\"\n",
        "try:\n",
        "    data_final.to_csv(processed_file_path, index=False)\n",
        "    print(\"Processed dataset saved successfully!\")\n",
        "    print(\"Processed dataset saved as:\", processed_file_path)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the processed dataset: {e}\")\n",
        "\n",
        "# Final output message\n",
        "print(f\"Final dataset shape: {data_final.shape}\")"
      ]
    },
    {
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Provide the file path to your dataset\n",
        "file_path = \"/content/RegresiUTSTelkom.csv\"\n",
        "try:\n",
        "    data = pd.read_csv(file_path)\n",
        "    print(\"Dataset successfully loaded!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found at {file_path}. Please check the file path and try again.\")\n",
        "    # exit() #Comment out exit to see if the file exists\n",
        "    #If you get past this point and data is still not defined check to see if the file exists\n",
        "    #If it exists then check the type and encoding when loading it with pd.read_csv\n",
        "    print(f\"The type of 'data' is: {type(data)}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\") #This helps see why the file potentially is not loaded\n",
        "    # exit() #Comment out exit to see if the file exists\n",
        "\n",
        "\n",
        "# Step 2: Rename columns to x1, x2, ..., xn\n",
        "column_names = [f'x{i+1}' for i in range(data.shape[1])]\n",
        "data.columns = column_names  # Ensure column renaming is clean\n",
        "print(\"Columns renamed successfully to:\", column_names)\n",
        "\n",
        "# Show basic info and first few rows\n",
        "print(\"Dataset Information:\")\n",
        "print(data.info())\n",
        "print(\"\\nFirst five rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Descriptive statistics\n",
        "print(\"\\nDescriptive statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Step 3: Drop duplicate rows (if not done already)\n",
        "data = data.drop_duplicates()\n",
        "print(f\"Duplicates removed. Data now has {data.shape[0]} rows and {data.shape[1]} columns.\")\n",
        "\n",
        "# Step 4: Remove Target Column (Assuming target is 'x1') for Feature Selection\n",
        "try:\n",
        "    target = data['x1']\n",
        "    data = data.drop(columns=['x1'])\n",
        "    print(\"Target column 'x1' successfully separated.\")\n",
        "except KeyError:\n",
        "    print(\"Target column 'x1' not found in the dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Step 5: Identifying and Removing Low Correlation Features with Target\n",
        "correlation_threshold = 0.1  # Threshold for correlation\n",
        "correlation_with_target = data.corrwith(target).abs()  # Correlation with target\n",
        "selected_features = correlation_with_target[correlation_with_target > correlation_threshold].index\n",
        "\n",
        "if selected_features.empty:\n",
        "    print(\"No features found with correlation above the threshold.\")\n",
        "    exit()\n",
        "else:\n",
        "    data_selected = data[selected_features]\n",
        "    print(f\"Selected features based on correlation threshold: {selected_features.tolist()}\")\n",
        "\n",
        "# Step 6: Variance Threshold to Remove Low Variance Features\n",
        "variance_threshold = 0.1  # Threshold for variance\n",
        "selector = VarianceThreshold(threshold=variance_threshold)\n",
        "try:\n",
        "    data_high_variance = selector.fit_transform(data_selected)\n",
        "    print(\"Low variance features removed.\")\n",
        "except ValueError:\n",
        "    print(\"Error: No feature met the variance threshold. Adjust the threshold and try again.\")\n",
        "    exit()\n",
        "\n",
        "# Convert data_high_variance back to DataFrame after Variance Threshold\n",
        "data_final = pd.DataFrame(data_high_variance, columns=[col for col, keep in zip(data_selected.columns, selector.get_support()) if keep])\n",
        "print(f\"Data after variance thresholding has {data_final.shape[1]} features.\")\n",
        "\n",
        "# Step 7: Add the target column back to the processed data\n",
        "data_final['x1'] = target.values[:data_final.shape[0]]  # Adjusting if rows were dropped during processing\n",
        "print(\"Target column added back to the processed data.\")\n",
        "\n",
        "# Step 8: Save the processed dataset\n",
        "processed"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "JI5byiNlY2xa",
        "outputId": "3e3f4cbb-98c7-4570-e037-9f33be2b795c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found at /content/RegresiUTSTelkom.csv. Please check the file path and try again.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4f45cd9ae464>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset successfully loaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/RegresiUTSTelkom.csv'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4f45cd9ae464>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#If you get past this point and data is still not defined check to see if the file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#If it exists then check the type and encoding when loading it with pd.read_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The type of 'data' is: {type(data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"An unexpected error occurred: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#This helps see why the file potentially is not loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    }
  ]
}